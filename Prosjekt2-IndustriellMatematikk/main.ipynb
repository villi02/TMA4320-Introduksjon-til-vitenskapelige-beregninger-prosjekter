{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/0pv5jqcs6h34_x160t92550h0000gn/T/ipykernel_8599/1927056692.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from layers import *\n",
    "from neural_network import NeuralNetwork\n",
    "from utils import onehot\n",
    "from data_generators import get_train_test_sorting\n",
    "from data_generators import get_train_test_addition\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 1 - Forstå hvordan datasettene og transformermodellen er strukturert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------\n",
    "##### 1.1 Gi et eksempel (som i likning $(10)$) på hvordan et datasett ${x, y}$ ville sett ut for å trene en transformermodell for å predikere et heltall $d$ gitt $d = a · b + c$ der $a, c$ er tosifrede heltall, mens $b$ er et ettsifret heltall, altså $9 ≥ b ∈ Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et sett av treningsdata kan genereres ved å la x bestå av sifrene i $a, b, c$ og alle sifrene i $d$ med unntak av det siste og lar $y = d$. Dermed vil formen for x være gitt ved $x = [a_0 , \\cdot \\cdot \\cdot, a_{r-1}, b_0, \\cdot \\cdot \\cdot, b_{r-1}, c_0, \\cdot \\cdot \\cdot, c_{r-1}, d_0, \\cdot \\cdot \\cdot, d_{r-1}]$. Gitt betingelsene i oppgaven over, la $r$ = 2, $a$ = 24, $b$ = 4, $c$ = 15 og dermed <br> $d$ = 111.  som gir oss x = $[2, 4, 4, 1, 5, 1, 1]$ og $y = [1, 1, 1]$. Merk at siste siffer i $d$ ikke er del av datasettet i x.  Modellen skal da gi $\\hat{z}$. Lengden av $\\hat{z}$, $n$, vil være gitt av lengden av x som har med lengden $n$. $\\hat{z}$ = [$\\hat{z}_0$, \\cdot \\cdot \\cdot, $\\hat{z}_5$] =  $f_{\\theta}([2, 4, 4, 1, 5, 1, 1])$. Ideelt er $\\theta$ optimert til en slik grad at <Br> $\\hat{y} = [\\hat{z}_3, \\hat{z}_4, \\hat{z}_5] = [1, 1, 1] = y$ er korrekt predikert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------\n",
    "##### 1.2) Når optimeringen er ferdig, hvordan kan vi bruke modellen $f_{\\theta}$  til å predikere $d$ gitt $a, b, c$? Vis dette med et eksempel, på samme måte som i likning $(11)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gitt at optmeringen er ferdig, kan modellen korrekt predikere $d$. Denne prossesen av å predikere de neste sifferene i seqvensen gjøres fra å lære av de oppgitte datasettene. Følgende tabell viser hvordan dette fungerer. La verdiene være det samme som i forrige oppgave, $r = 2, a = 24, b = 4,$<Br> $c = 15$\n",
    "\n",
    "| Iterasjoner | Modell |\n",
    "|----------|----------|\n",
    "| $x^{(0)} = [2, 4, 0, 4, 1, 5]$ | $[\\hat{z}_0^{(0)}, \\hat{z}_1^{(0)}, \\hat{z}_2^{(0)}, \\hat{z}_3^{(0)}] = f_{\\theta}(x^{(0)})$|\n",
    "| $x^{(1)} = [2, 4, 0, 4, 1, 5, \\hat{z}_3^{(0)}]$ | $[\\hat{z}_0^{(1)}, \\cdot \\cdot \\cdot, \\hat{z}_4^{(1)}] = f_{\\theta}(x^{(1)})$ |\n",
    "| $x^{(2)} = [2, 4, 0, 4, 1, 5, \\hat{z}_3^{(0)}, \\hat{z}_4^{(1)}]$ | $[\\hat{z}_0^{(2)}, \\cdot \\cdot \\cdot, \\hat{z}_5^{(2)}] = f_{\\theta}(x^{(2)})$  |\n",
    "| $x^{(3)} = [2, 4, 0, 4, 1, 5, \\hat{z}_3^{(0)}, \\hat{z}_4^{(1)}, \\hat{z}_5^{(2)}]$ |  |\n",
    "\n",
    "Disse predikasjonene hentes ut og returneres som $\\hat{y} = [\\hat{z}_3^{(0)}, \\hat{z}_4^{(1)}, \\hat{z}_5^{(2)}]$ som bør være likt $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------\n",
    "##### 1.3) Anta at vi bruker cross-entropy som objektfunksjon, at $m = 5$ og $y = [4, 3, 2, 1]$. Hvilke diskret sannsynlighetsfordeling $\\hat{Y}$ ville gitt en objektfunksjon $L(θ, D) = 0$? Hva ville $\\hat{y}$ vært i dette tilfellet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy er gitt ved $L(θ, D) = -\\frac{1}{D \\cdot n} \\sum_{i=0}^{D-1} \\sum_{j=0}^{n-1} \\log \\hat{Y}_{k,j}^{(i)}$ hvor $D$ er datapunktene, $\\theta $\n",
    "er parameterne, og $\\hat{Y}$ er sannsynlighetsfordelingen til den predikterte modellen, samt er $j$ og $i$ dimensjonene til $\\hat{Y}$. Det objektfunksjonen gjør er å sammenligne onehot(y) med $\\hat{Y}$. Hvis $L(θ, D) = 0$ vil den optimerte modellen og onehot(y) være identiske. Når dette inntreffer vil $argmax_{\\text{col}}(\\hat{Y})$ = $\\hat{y}$ som igjen er lik $y$. I dette tilfellet er $y = [4,3,2,1]$, som også vil være lik $\\hat{y}$.\n",
    "$\\hat{Y}$ vil være gitt av den diskrete sannsynlighetsfordelingen:<Br><Br> $\\hat{Y}$ =\n",
    "$\\left[\\begin{array}{ccc}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1\\\\\n",
    "0 & 0 & 1 & 0\\\\\n",
    "0 & 1 & 0 & 0\\\\\n",
    "1 & 0 & 0 & 0\\\\\n",
    "\\end{array}\\right]$ , <Br><Br> som er lik onehot($[4,3,2,1]$). Dette betyr i praksis at paramtetrene i transformenmodellen klarer å prediktere hva som kommer videre i sekvensen og vi ender opp med samme antatt løsning ($\\hat{y}$) som faktisk løsning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------\n",
    "##### 1.4) Gitt $d, m, n_{max}, k, p$ og $L$. Hvor mange enkeltparametre har en transformermodell? Med enkeltparametre mener vi hvor mange tall $w ∈ R$ vi må bestemme ved optimering. En matrise $W ∈ R^{m×n}$ består av $m · n$ tall eller enkeltparametre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med gitte variabler for $d, m, n_{max}, k, p$ og  $L$ er antall enkeltparametre mulig å bestemme. Enkeltparametre er gitt med $w \\in \\mathbb{R}$ noe som uttrykkes med å se på dimensjoner for ulike parametermatriser i transformermodellen.\n",
    "\n",
    "$W_E$ og $W_P$ har henholdsvis dimensjonene $W_E \\in \\mathbb{R}^{d \\times m}$ og $ W_P \\in \\mathbb{R}^{d \\times n_{max}} $ som representerer parametermatrisen til en sekvens for x med lengde n, som skrives som $z_0$. I tilegg ønskes det å gjøre $L$ paramtriserte trasformasjoner på $z_0$, så man ender opp med $L \\cdot (d \\times m + d \\times n_{max})$ for embedding delen av enkeltparamtrene. Under unenbeddingen oppstår en ny parametermatrise $W_U$ som er en sekvens med lengde $n$ med heltall opp til $m$, den har dimensjonene $ W_U \\in \\mathbb{R}^{d \\times m} $. Attention-lag bidrar også til antall enkeltparamtre for transformmodellen, der har man 4 parametermatriser; $W_O, W_V, W_Q, W_K$ alle med samme dimensjon $\\mathbb{R}^{k \\times d} $. Transformermodellen har også en $feed$-$forward $ del som bidrar med to paramtermatriser $W_1$ og $W_2$ begge med dimensjoner $\\mathbb{R}^{p \\times d} $\n",
    "\n",
    "\n",
    "Hvis man tar disse parametermatrisene i betrakning og antar at $k < d < p$ vil man ha: \n",
    "$w = d \\times m+L\\cdot (d \\times m + d \\times n_{max}) + 4 \\cdot k \\times d + 2 \\cdot p \\times d $, enkeltparametre. (siden k og p er heltall man bestemmer selv er dette en rimelig antagelse å ta).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------\n",
    "##### 1.5 Transformermodellen er gitt i likningene $(4) - (9)$. La $n = n_{max} = 1,$  $m = d = k = p=2$ og $L=1$. Anta videre at $W_O = W_V = W_Q = W_K = W_1 = W_2 = W_U = I_{2×2}$ og at $σ(x) = Relu(x) = max(0, x)$. Dersom <Br> $W_E = \\left[\\begin{array}{ccc} 1 & 0 \\\\ 0 & \\alpha \\end{array} \\right]$ , og $W_P$ = $\\left[\\begin{array}{ccc} 1 \\\\ 0 \\end{array} \\right]$ vis at vi må ha $\\alpha > 1$ for å få  $\\hat{z} = [1]$ som output når input er $x = [1]$.\n",
    "*  *  *  * * * * * * * * * * * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Med variablene oppgitt i oppgaven $L=n = n_{max}= x = 1$ og $m=d=k=p=d = 2$ og alle parametermatrisene lik\n",
    "\n",
    "$\\left[\\begin{array}{ccc}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{array}\\right]$ = $ I_{2\\times 2}$ , utenom $W_E = \\left[\\begin{array}{ccc}\n",
    "1 & 0 \\\\\n",
    "0 & \\alpha\n",
    "\\end{array}\\right]$ , og $W_P = \\left[\\begin{array}{ccc}\n",
    "1 \\\\\n",
    "0 \n",
    "\\end{array}\\right]$\n",
    "\n",
    "Med dette oppgitt vil  $ X = onehot(x) = \\left[\\begin{array}{ccc}0 \\\\1 \n",
    "\\end{array}\\right]$ som resulterer i en $z_0 = \\left[\\begin{array}{ccc}0 \\\\ \\alpha \n",
    "\\end{array}\\right]+ \\left[\\begin{array}{ccc}1 \\\\ 0 \n",
    "\\end{array}\\right]$ =$\\left[\\begin{array}{ccc}1 \\\\ \\alpha \n",
    "\\end{array}\\right]$. For å videre bestemme et uttrykk for $\\hat{z}$ må vi se på hva transformermodellen gjør med $z_0$. \n",
    "\n",
    "Videre er $z_{1/2}$ = $z_0 + W_O^T  W_V  z_0 A(z_0)$, hvor $A(z_0)$ = $softmax_{col}(z_0^T W_Q^T W_K z_0+D)$ og D sørger for at den strengt nedre delen av A er 0.\n",
    "Ved å løse $A(z_0)$ får man utrykket $(1+ \\alpha ^2)$ i softmax funksjonen.\n",
    "\n",
    "$z_{1/2} = \\left[\\begin{array}{ccc}1 \\\\ \\alpha \n",
    "\\end{array}\\right] + I_{2 \\times 2} I_{2 \\times 2} \\left[\\begin{array}{ccc}1 \\\\ \\alpha \n",
    "\\end{array}\\right] softmax(1+ \\alpha ^2)$ = $ 2 \\left[\\begin{array}{ccc}1 \\\\ \\alpha \n",
    "\\end{array}\\right]$ ettersom softmax av et utrykk tilsvarer å dele på seg selv i e-potens, som resulterer at utrykket blir lik 1.\n",
    "\n",
    "for $z_1$ får vi et uttrykk som er $z_{1/2} + W_2^T \\sigma (W_1 z_{1/2})$, $\\sigma$ er en aktiveringsfunskjon, i dette tilfelle kan man bruke $relu(W_1 z_{1/2})$.\n",
    "Utrykket blir da:\n",
    "\n",
    "$z_1 = 2  \\left[\\begin{array}{ccc}1 \\\\ \\alpha \n",
    "\\end{array}\\right]+ I_{2 \\times 2} max(0,I_{2 \\times 2} 2 \\left[\\begin{array}{ccc}1 \\\\ \\alpha \n",
    "\\end{array}\\right]) $ = $ 4  \\left[\\begin{array}{ccc}1 \\\\ \\alpha \n",
    "\\end{array}\\right]$\n",
    " \n",
    "Ved hjelp av $z_1$ kan man ta i bruk likning $(8)$ for å finne sannsynlighetsfunksjonen $Z$.\n",
    "\n",
    " $Z = softmax_{col}(W_U^T Z_1)$ $,$ her vil argumentet $W_U^T z_1$ bli lik $z_1$, og softmax vil returnere $Z = \\frac{1}{e^4 + e^{4 \\alpha}} \\left[\\begin{array}{ccc}e^4 \\\\ e^{4 \\alpha }\n",
    "\\end{array}\\right]$\n",
    "\n",
    "for å få $\\hat{z} = [1]$ må $argmax(Z)$ bli 1, og dette krever at verdien på indeks [1] må være større enn den på indeks [0], da må $e^4 < e^{4 \\alpha}$ og dette impliserer at $\\alpha >1$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------\n",
    "## Oppgave 2 - Objektorientert programmering for transformermodell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 I den utdelte koden layers.py og neural network.py finnes en objektorientert implementering av et nevralt nettverk som kan ha lineære lag og en Relu- aktiveringsfunksjon. I tillegg er embedding og posisjonsenkoding samt feed-forward lag implementert.<Br> Forklar hvordan NeuralNetwork bruker arv, eller inheritance, for å utføre en iterasjon av gradient descent (stepgd()) hvis vi antar det er initiert med minst ett LinearLayer i listen layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et nevralt nettverk lærer gjennom mange små gradevis forbedringer gjort gjennom å prøve og feile. Denne prossen består av mange ulike funksjoner og operasjoner, som beskrevet i forrige oppgave. Dette gjøres med formålet om å utføre en gradient descent. Før at det nevralenettverket skal fungere må layers initieres.\n",
    " \n",
    "Layers er en klasse som fungerer som en base klasse for alle andre typer layers i nettverket, som representerer de ulike prossesene det nevralenettveket utfører. Her implementeres en basis versjon av metoder som forward(), backward() og step_gd(). Dette vil si at hvis et objekt arver fra Layers klassen så vil det objektet har metodene forward(), backward() og step_gd(). Derved vil alle layers som arver fra Layers base klassen implementere eller overskrive disse metodene med kode tilrettet hver individuelle layer. Denne strukturen tillater også at et lag har en egen spesifiserte step_gd() med at det kan overskrive metoden til å være mest hensiktsmessig for det spesifikke laget. Resultatet av dette gjør at neural_network kan operere på et høyere abstraksjonsnivå og kan implementere \"universelle\" metoder som step_gd() uten å ta hensyn til de ulike spesifikke detaljene til hvert lag. \n",
    "\n",
    "Mer spesifikt bruker neural_network arv til å kunne behandle alle sine layers på samme måte, selv om de kan ha forskjellig implementerte step_gd() metoder. Polymorfisme lar da neural_network kalle samme funksjon (step_gd()) på samme måte for hvert lag uten å vite hvilken subklasse hvert layer tilhører. Dermed kan hver operasjon som nural_network utfører kalles gjennom bruk av forward(), for å finne objektfunksjonen, backwards(), for å resette og oppdatere verdiene i nettverket, og step_gd() for å optimalisere vektingen og biasene i treningen av nettverket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "#### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "##### 3.3 Implementer en funksjon som sorterer en sekvens a, på samme måte som kapittel 3.1.2 og rapporter hvor stor andel av disse sekvensene du klarte å sortere riktig. Hvis du regner ut hvor mange mulige sekvenser av lengde r = 5 med 0 og 1 det er mulig å generere, ser du kanskje at det er umulig å teste på nye sekvenser.\n",
    "\n",
    "Før et nevraltnettverk kan returnere korrekt output til en gitt input må den trenes. Denne treningen gjøres gjennom å prossesen beskrevet i de tidligere oppgavene ved å bruke et datasett for optimalisere outputet. Ideelt skal det nevralenettverket trenes på et stort datasett før det testes med ny data som ikke ble brukt i testing fasen. Dette gjøre for å kunne observere om det nevralenettverket kan korrekt predikere et resultat fra ny data istedet for å kun gjengi et resultat det tidligere har sett at er riktig respons til et gitt input.\n",
    "\n",
    "Dette er desverre vaskelig for et nevraltnettverk som skal lære seg å sortere en sekvens som $a$. Sekvensen $a$ er gitt ved parameterene $r = 5$ og $m = 2$. Dette betyr at sekvensen består av fem siffer og har to mulige siffer hvert element i sekvensen kan være, her 0 og 1. Dermed er antallet, $n$, for unike sekvenser som $a$ kan bestå av, være gitt ved $n = 2^5 = 32$. I tilegg er det kun 6 sekvenser som kan være riktig svar. I en tidligere iterasjon av koden ville programmet optimaliseres inn i et \"lokalt optima\" hvor den gjette $z = [0, 0, 0, 1, 1]$ på alle  ettersom dette er svaret som forekommer oftest i test dataen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before training 0.0%\n",
      "Epoch 10/150, Average Loss: 0.04979227823749301\n",
      "Epoch 20/150, Average Loss: 0.0005045500977796062\n",
      "Epoch 30/150, Average Loss: 7.196866185529765e-05\n",
      "Epoch 40/150, Average Loss: 3.521432831710335e-05\n",
      "Epoch 50/150, Average Loss: 2.3231545055270278e-05\n",
      "Epoch 60/150, Average Loss: 1.728834252117613e-05\n",
      "Epoch 70/150, Average Loss: 1.3506694867566914e-05\n",
      "Epoch 80/150, Average Loss: 1.0870771664895161e-05\n",
      "Epoch 90/150, Average Loss: 8.909773743268677e-06\n",
      "Epoch 100/150, Average Loss: 7.4304073386731195e-06\n",
      "Epoch 110/150, Average Loss: 6.264179205187376e-06\n",
      "Epoch 120/150, Average Loss: 5.330057942350493e-06\n",
      "Epoch 130/150, Average Loss: 4.5728962139558695e-06\n",
      "Epoch 140/150, Average Loss: 3.952441473337735e-06\n",
      "Epoch 150/150, Average Loss: 3.437108395717347e-06\n",
      "\n",
      "Accuracy after training 100.0%\n"
     ]
    }
   ],
   "source": [
    "#training the module\n",
    "r = 5\n",
    "m = 2\n",
    "d = 20\n",
    "k = 5\n",
    "p = 25\n",
    "L = 2\n",
    "n_max = 2*r - 1\n",
    "n_iter = 150\n",
    "alpha = 0.001\n",
    "num_of_samples = 250\n",
    "num_train_batches = 10\n",
    "num_test_batches = 1\n",
    "\n",
    "data = get_train_test_sorting(r, m, num_of_samples, num_train_batches,num_test_batches)\n",
    "\n",
    "loss = CrossEntropy()\n",
    "feed_forward1 = FeedForward(d,p)\n",
    "attention1 = Attention(d,k)\n",
    "feed_forward2 = FeedForward(d,p)\n",
    "attention2 = Attention(d,k)\n",
    "embed_pos = EmbedPosition(n_max,m,d)\n",
    "un_embed_pos = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "layers = [embed_pos, attention1, feed_forward1,attention2, feed_forward2, un_embed_pos, softmax]\n",
    "nueralnetsortwil = NeuralNetwork(layers)\n",
    "\n",
    "x = data['x_train']\n",
    "y = data['y_train']\n",
    "x_t = data['x_test'][0]\n",
    "y_t = data['y_test'][0]\n",
    "\n",
    "per, y_hat = sorting(nueralnetsortwil, x_t, y_t,m, r)\n",
    "print(f'Accuracy before training {per*100}%')\n",
    "\n",
    "arr2 = algorithm_4_sort_finished(x, y, n_iter, alpha, m, nueralnetsortwil, r)\n",
    "\n",
    "per_after, y_hat_after = sorting(nueralnetsortwil, x_t, y_t,m, r)\n",
    "print(f'\\nAccuracy after training {per_after*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy after training 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nAccuracy after training {per_after*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0,len(arr2),len(arr2)),arr2)\n",
    "plt.xlabel('Iterasjoner')\n",
    "plt.ylabel('Logaritmen av losset')\n",
    "plt.title('Plot av feil')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 med r=7 og m=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prosent av antall riktige sorteringer før trening er 0.0%\n",
      "Epoch 10/250, Average Loss: 0.3779759773627782\n",
      "Epoch 20/250, Average Loss: 0.2634570787262456\n",
      "Epoch 30/250, Average Loss: 0.2078427066855776\n",
      "Epoch 40/250, Average Loss: 0.18289821640057108\n",
      "Epoch 50/250, Average Loss: 0.1703087396465034\n",
      "Epoch 60/250, Average Loss: 0.15648591493258052\n",
      "Epoch 70/250, Average Loss: 0.1455187224451499\n",
      "Epoch 80/250, Average Loss: 0.1383105170219475\n",
      "Epoch 90/250, Average Loss: 0.13137846047912083\n",
      "Epoch 100/250, Average Loss: 0.12333302939793686\n",
      "Epoch 110/250, Average Loss: 0.11207561265898251\n",
      "Epoch 120/250, Average Loss: 0.09857102040680678\n",
      "Epoch 130/250, Average Loss: 0.09343675451176969\n",
      "Epoch 140/250, Average Loss: 0.12047393077064046\n",
      "Epoch 150/250, Average Loss: 0.13803485272887464\n",
      "Epoch 160/250, Average Loss: 0.1480852437153334\n",
      "Epoch 170/250, Average Loss: 0.13437192745580293\n",
      "Epoch 180/250, Average Loss: 0.12094148173890765\n",
      "Epoch 190/250, Average Loss: 0.12691707775952127\n",
      "Epoch 200/250, Average Loss: 0.11943056718049612\n",
      "Epoch 210/250, Average Loss: 0.1009737530340605\n",
      "Epoch 220/250, Average Loss: 0.09030069629502749\n",
      "Epoch 230/250, Average Loss: 0.09015048844332377\n",
      "Epoch 240/250, Average Loss: 0.1175527982326976\n",
      "Epoch 250/250, Average Loss: 0.11912891615738168\n"
     ]
    }
   ],
   "source": [
    "#training the module\n",
    "r = 7\n",
    "m = 5\n",
    "d = 20\n",
    "k = 10\n",
    "p = 25\n",
    "L = 2\n",
    "n_max = 2*r - 1\n",
    "n_iter = 250\n",
    "alpha = 0.001\n",
    "num_of_samples = 250\n",
    "num_train_batches = 10\n",
    "num_test_batches = 1\n",
    "\n",
    "data = get_train_test_sorting(r, m, num_of_samples, num_train_batches,num_test_batches)\n",
    "\n",
    "loss = CrossEntropy()\n",
    "feed_forward1 = FeedForward(d,p)\n",
    "attention1 = Attention(d,k)\n",
    "feed_forward2 = FeedForward(d,p)\n",
    "attention2 = Attention(d,k)\n",
    "embed_pos = EmbedPosition(n_max,m,d)\n",
    "un_embed_pos = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "layers = [embed_pos, attention1,feed_forward1,attention2, feed_forward2, un_embed_pos, softmax]\n",
    "nueralnetsortlong = NeuralNetwork(layers)\n",
    "\n",
    "x = data['x_train']\n",
    "y = data['y_train']\n",
    "x_t = data['x_test'][0]\n",
    "y_t = data['y_test'][0]\n",
    "\n",
    "per, y_hat = sorting(nueralnetsortlong, x_t, y_t,m, r)\n",
    "print(f'prosent av antall riktige sorteringer før trening er {per*100}%')\n",
    "\n",
    "arr332 = algorithm_4_sort_finished(x, y, n_iter, alpha, m, nueralnetsortlong, r)\n",
    "\n",
    "per_after, y_hat_after = sorting(nueralnetsortlong, x_t, y_t,m, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy after training 37.2%\n",
      "xt = [1. 3. 2. 0. 4. 0. 3.] yt = [0. 0. 1. 2. 3. 3. 4.] and z = [0. 0. 1. 2. 3. 3. 4.]\n",
      "xt = [3. 1. 2. 3. 2. 1. 2.] yt = [1. 1. 2. 2. 2. 3. 3.] and z = [0. 1. 1. 2. 2. 3. 3.]\n",
      "xt = [0. 1. 0. 4. 1. 1. 4.] yt = [0. 0. 1. 1. 1. 4. 4.] and z = [0. 0. 1. 1. 1. 4. 4.]\n",
      "xt = [2. 2. 3. 3. 2. 3. 1.] yt = [1. 2. 2. 2. 3. 3. 3.] and z = [0. 1. 2. 2. 3. 3. 3.]\n",
      "xt = [0. 3. 3. 2. 2. 3. 1.] yt = [0. 1. 2. 2. 3. 3. 3.] and z = [1. 2. 2. 2. 3. 3. 3.]\n",
      "xt = [4. 2. 4. 1. 3. 1. 3.] yt = [1. 1. 2. 3. 3. 4. 4.] and z = [0. 1. 2. 3. 3. 4. 4.]\n",
      "xt = [3. 2. 0. 3. 0. 0. 4.] yt = [0. 0. 0. 2. 3. 3. 4.] and z = [1. 2. 2. 3. 3. 3. 4.]\n",
      "xt = [3. 2. 0. 1. 0. 0. 4.] yt = [0. 0. 0. 1. 2. 3. 4.] and z = [1. 1. 1. 2. 2. 3. 4.]\n",
      "xt = [4. 3. 0. 1. 3. 2. 0.] yt = [0. 0. 1. 2. 3. 3. 4.] and z = [0. 1. 1. 3. 3. 3. 4.]\n",
      "xt = [3. 0. 0. 4. 0. 1. 1.] yt = [0. 0. 0. 1. 1. 3. 4.] and z = [0. 0. 0. 1. 2. 3. 4.]\n",
      "xt = [3. 2. 4. 1. 0. 3. 0.] yt = [0. 0. 1. 2. 3. 3. 4.] and z = [0. 1. 2. 2. 3. 3. 4.]\n",
      "xt = [4. 4. 2. 0. 0. 2. 1.] yt = [0. 0. 1. 2. 2. 4. 4.] and z = [0. 0. 0. 0. 1. 4. 4.]\n",
      "xt = [1. 0. 2. 4. 2. 4. 4.] yt = [0. 1. 2. 2. 4. 4. 4.] and z = [1. 2. 1. 2. 4. 4. 4.]\n",
      "xt = [4. 0. 1. 2. 4. 2. 0.] yt = [0. 0. 1. 2. 2. 4. 4.] and z = [0. 0. 1. 2. 2. 4. 4.]\n",
      "xt = [2. 1. 2. 2. 2. 4. 0.] yt = [0. 1. 2. 2. 2. 2. 4.] and z = [0. 1. 1. 2. 2. 2. 4.]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nAccuracy after training {per_after*100}%')\n",
    "for i in range(15):\n",
    "    print(f'xt = {x_t[i]} yt = {y_t[i]} and z = {y_hat_after[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0,len(arr332),len(arr332)),arr332)\n",
    "plt.xlabel('Iterasjoner')\n",
    "plt.ylabel('Losset')\n",
    "plt.title('Plot av feil')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prosent av antall riktige sorteringer før trening er 0.0%\n",
      "xt = [1. 4. 4. 2. 2. 4. 2.] yt = [1. 2. 2. 2. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 2. 1. 4. 0. 1.] yt = [0. 1. 1. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 2. 4. 4. 1. 4.] yt = [0. 1. 1. 2. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 2. 2. 4. 0. 0.] yt = [0. 0. 2. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 1. 4. 1. 0. 0.] yt = [0. 0. 0. 1. 1. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 0. 3. 2. 3. 2.] yt = [0. 2. 2. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 1. 2. 3. 3. 1.] yt = [0. 1. 1. 1. 2. 3. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 4. 2. 0. 4. 4. 2.] yt = [0. 1. 2. 2. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 1. 3. 0. 0. 1. 3.] yt = [0. 0. 0. 1. 1. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 3. 4. 1. 4. 1.] yt = [0. 1. 1. 2. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 2. 3. 4. 4. 2. 3.] yt = [2. 2. 3. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 4. 2. 1. 4. 2. 0.] yt = [0. 1. 1. 2. 2. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 2. 0. 4. 2. 2.] yt = [0. 0. 2. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 2. 0. 3. 0. 2.] yt = [0. 0. 2. 2. 3. 3. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 0. 1. 2. 4. 4.] yt = [0. 1. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 2. 4. 0. 3. 1.] yt = [0. 0. 1. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 4. 3. 2. 2. 4. 1.] yt = [0. 1. 2. 2. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 4. 4. 4. 2. 2.] yt = [1. 2. 2. 2. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 3. 1. 4. 0. 3.] yt = [0. 1. 3. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 4. 2. 1. 3. 2.] yt = [1. 1. 2. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 0. 2. 2. 0. 1. 0.] yt = [0. 0. 0. 0. 1. 2. 2.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 0. 3. 3. 4. 2.] yt = [0. 0. 2. 3. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 4. 3. 4. 3. 1. 1.] yt = [1. 1. 1. 3. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 4. 1. 2. 2. 0.] yt = [0. 0. 1. 2. 2. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 4. 3. 1. 0. 0. 0.] yt = [0. 0. 0. 1. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 1. 0. 2. 0. 3.] yt = [0. 0. 1. 2. 2. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 1. 3. 3. 4. 1.] yt = [0. 1. 1. 3. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 4. 4. 0. 1. 4.] yt = [0. 0. 1. 2. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 4. 3. 2. 1. 2.] yt = [0. 1. 2. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 0. 4. 0. 3. 2. 4.] yt = [0. 0. 0. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 4. 4. 4. 2. 4.] yt = [0. 2. 3. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 2. 0. 4. 4. 4.] yt = [0. 2. 3. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 4. 4. 0. 1. 3.] yt = [0. 0. 1. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 4. 4. 1. 2. 2. 2.] yt = [0. 1. 2. 2. 2. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 4. 2. 4. 2. 0. 4.] yt = [0. 2. 2. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 4. 4. 3. 1. 1. 4.] yt = [1. 1. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 1. 2. 4. 3. 0.] yt = [0. 1. 1. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 4. 4. 4. 3. 3.] yt = [3. 3. 3. 4. 4. 4. 4.] and z = [3. 4. 3. 4. 0. 2. 0.]\n",
      "xt = [0. 1. 4. 0. 1. 3. 0.] yt = [0. 0. 0. 1. 1. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 4. 1. 3. 1. 4.] yt = [1. 1. 2. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 3. 2. 2. 0. 3.] yt = [0. 2. 2. 2. 3. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 3. 4. 1. 4. 0.] yt = [0. 0. 1. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 0. 2. 2. 0. 3. 1.] yt = [0. 0. 0. 1. 2. 2. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 0. 4. 0. 4. 4.] yt = [0. 0. 0. 1. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 4. 2. 0. 0. 0.] yt = [0. 0. 0. 0. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 1. 4. 2. 0. 0.] yt = [0. 0. 0. 1. 1. 2. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 2. 0. 0. 0. 2. 1.] yt = [0. 0. 0. 1. 2. 2. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 3. 1. 4. 0. 2.] yt = [0. 1. 2. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 2. 4. 2. 0. 3. 3.] yt = [0. 0. 2. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 1. 1. 1. 2. 0.] yt = [0. 1. 1. 1. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 3. 4. 4. 1. 0.] yt = [0. 1. 1. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 0. 3. 4. 0. 3.] yt = [0. 0. 1. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 0. 0. 2. 1. 2. 1.] yt = [0. 0. 0. 1. 1. 2. 2.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [2. 2. 1. 3. 3. 0. 3.] yt = [0. 1. 2. 2. 3. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 1. 0. 0. 0. 1.] yt = [0. 0. 0. 1. 1. 2. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 4. 4. 4. 1. 3. 1.] yt = [1. 1. 3. 4. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 2. 4. 3. 4. 4.] yt = [0. 2. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 2. 4. 1. 4. 4.] yt = [0. 1. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 4. 1. 2. 4. 4.] yt = [1. 2. 2. 2. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 0. 3. 3. 2. 4.] yt = [0. 2. 2. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 2. 3. 1. 1. 3.] yt = [0. 1. 1. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 4. 0. 0. 4. 1.] yt = [0. 0. 1. 1. 2. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 0. 0. 4. 4. 0.] yt = [0. 0. 0. 1. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 3. 2. 0. 3. 2. 2.] yt = [0. 1. 2. 2. 2. 3. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 4. 3. 0. 2. 1. 1.] yt = [0. 1. 1. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 4. 3. 2. 1. 3.] yt = [0. 1. 1. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 4. 2. 0. 3. 1.] yt = [0. 1. 2. 3. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 4. 0. 0. 3. 2.] yt = [0. 0. 2. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 0. 1. 0. 1. 1.] yt = [0. 0. 1. 1. 1. 1. 3.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [2. 3. 3. 0. 0. 4. 4.] yt = [0. 0. 2. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 3. 0. 2. 2. 1.] yt = [0. 1. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 4. 4. 2. 0. 4.] yt = [0. 2. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 4. 4. 2. 1. 1. 4.] yt = [0. 1. 1. 2. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 3. 4. 1. 3. 2.] yt = [1. 2. 2. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 2. 2. 2. 3. 0. 2.] yt = [0. 2. 2. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 0. 2. 2. 4. 2. 3.] yt = [0. 0. 2. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 4. 4. 0. 3. 2. 1.] yt = [0. 1. 2. 2. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 2. 1. 2. 4. 1.] yt = [0. 1. 1. 2. 2. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 0. 2. 4. 4. 2.] yt = [0. 2. 2. 3. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 2. 0. 1. 2. 4. 2.] yt = [0. 1. 2. 2. 2. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 3. 1. 2. 1. 0.] yt = [0. 0. 1. 1. 1. 2. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 4. 3. 1. 2. 1.] yt = [1. 1. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 1. 3. 0. 1. 1.] yt = [0. 0. 1. 1. 1. 2. 3.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [0. 0. 0. 1. 3. 0. 4.] yt = [0. 0. 0. 0. 1. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 2. 2. 0. 2. 3.] yt = [0. 0. 2. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 0. 0. 2. 4. 1.] yt = [0. 0. 1. 2. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 3. 0. 2. 3. 3.] yt = [0. 2. 3. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 1. 0. 3. 3. 2. 1.] yt = [0. 0. 1. 1. 2. 3. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 1. 3. 1. 1. 3.] yt = [1. 1. 1. 2. 2. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 2. 2. 2. 3. 3.] yt = [0. 1. 2. 2. 2. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 3. 4. 3. 0. 3. 1.] yt = [0. 1. 1. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 0. 0. 4. 3. 2.] yt = [0. 0. 1. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 4. 2. 3. 0. 4. 3.] yt = [0. 2. 2. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 0. 3. 2. 0. 0. 0.] yt = [0. 0. 0. 0. 2. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 2. 2. 2. 3. 3.] yt = [2. 2. 2. 2. 3. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 3. 0. 3. 0. 0.] yt = [0. 0. 0. 2. 3. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 2. 1. 1. 2. 0.] yt = [0. 0. 1. 1. 1. 2. 2.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [4. 2. 0. 3. 3. 2. 2.] yt = [0. 2. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 4. 4. 3. 0. 4.] yt = [0. 0. 3. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 1. 2. 0. 3. 3.] yt = [0. 0. 1. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 2. 2. 4. 4. 3. 0.] yt = [0. 0. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 4. 0. 4. 0. 3.] yt = [0. 0. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 1. 3. 2. 2. 1. 4.] yt = [1. 1. 1. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 3. 2. 1. 1. 2.] yt = [1. 1. 1. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 0. 0. 2. 2. 1.] yt = [0. 0. 1. 2. 2. 2. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 4. 2. 4. 0. 3.] yt = [0. 1. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 0. 1. 3. 4. 0. 3.] yt = [0. 0. 0. 1. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 0. 4. 4. 4. 4.] yt = [0. 1. 2. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 4. 4. 1. 4. 4. 3.] yt = [1. 3. 4. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 4. 2. 1. 3. 4.] yt = [1. 1. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 1. 3. 4. 3. 2.] yt = [1. 2. 3. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 4. 4. 3. 2. 0.] yt = [0. 1. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 2. 2. 2. 1. 3.] yt = [1. 1. 2. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 4. 0. 0. 2. 1.] yt = [0. 0. 0. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 2. 3. 4. 3. 3.] yt = [2. 3. 3. 3. 3. 4. 4.] and z = [3. 4. 3. 4. 0. 2. 0.]\n",
      "xt = [2. 1. 1. 1. 1. 0. 4.] yt = [0. 1. 1. 1. 1. 2. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 3. 2. 3. 4. 0.] yt = [0. 1. 2. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 2. 1. 3. 3. 4. 3.] yt = [0. 1. 2. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 1. 2. 4. 4. 4.] yt = [1. 1. 2. 2. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 0. 0. 2. 2. 0.] yt = [0. 0. 0. 0. 1. 2. 2.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 4. 3. 0. 4. 4.] yt = [0. 0. 1. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 4. 0. 1. 1. 3. 1.] yt = [0. 0. 1. 1. 1. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 4. 1. 2. 3. 3. 2.] yt = [0. 1. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 0. 2. 0. 2. 4.] yt = [0. 0. 1. 2. 2. 2. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 1. 3. 4. 1. 1.] yt = [1. 1. 1. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 4. 3. 3. 1. 4.] yt = [1. 3. 3. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 2. 2. 4. 4. 1. 4.] yt = [1. 2. 2. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 1. 2. 4. 2. 1.] yt = [1. 1. 1. 2. 2. 2. 4.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [2. 0. 0. 2. 4. 2. 0.] yt = [0. 0. 0. 2. 2. 2. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 2. 1. 1. 0. 0.] yt = [0. 0. 0. 1. 1. 2. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 2. 3. 3. 0. 2. 3.] yt = [0. 2. 2. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 4. 0. 3. 1. 2.] yt = [0. 1. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 2. 3. 4. 2. 0.] yt = [0. 0. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 1. 2. 4. 2. 3.] yt = [1. 2. 2. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 1. 1. 4. 4. 1. 2.] yt = [0. 1. 1. 1. 2. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 1. 1. 3. 4. 2. 4.] yt = [1. 1. 1. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 4. 4. 2. 4. 4.] yt = [2. 2. 3. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 2. 3. 2. 4. 1.] yt = [1. 2. 2. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 4. 4. 2. 3. 2.] yt = [2. 2. 3. 3. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 1. 1. 3. 4. 1.] yt = [1. 1. 1. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 0. 3. 4. 0. 3.] yt = [0. 0. 0. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 1. 2. 4. 4. 0. 0.] yt = [0. 0. 1. 1. 2. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 2. 3. 4. 0. 3.] yt = [0. 2. 3. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 2. 3. 2. 3. 2.] yt = [1. 2. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 2. 4. 3. 2. 4.] yt = [1. 2. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 4. 0. 2. 4. 4.] yt = [0. 0. 2. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 0. 1. 1. 3. 1.] yt = [0. 1. 1. 1. 1. 2. 3.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [2. 3. 4. 2. 3. 2. 2.] yt = [2. 2. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 0. 0. 4. 1. 4.] yt = [0. 0. 1. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 4. 4. 4. 0. 1. 0.] yt = [0. 0. 1. 2. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 1. 1. 0. 4. 1. 2.] yt = [0. 1. 1. 1. 1. 2. 4.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [2. 3. 2. 4. 2. 4. 3.] yt = [2. 2. 2. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 0. 0. 2. 3. 1.] yt = [0. 0. 1. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 0. 1. 0. 3. 3.] yt = [0. 0. 0. 1. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 2. 4. 0. 2. 0. 3.] yt = [0. 0. 0. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 4. 2. 0. 2. 2.] yt = [0. 2. 2. 2. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 1. 1. 4. 0. 3. 0.] yt = [0. 0. 0. 1. 1. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 3. 4. 1. 3. 4.] yt = [1. 1. 2. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 2. 3. 2. 3. 1.] yt = [1. 1. 2. 2. 3. 3. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 1. 1. 1. 1. 2.] yt = [1. 1. 1. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 4. 4. 2. 0. 4. 2.] yt = [0. 2. 2. 4. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 3. 3. 4. 0. 2. 0.] yt = [0. 0. 1. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 0. 2. 2. 4. 2.] yt = [0. 2. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 2. 4. 3. 2. 2.] yt = [0. 1. 2. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 2. 4. 0. 0. 1.] yt = [0. 0. 0. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 0. 1. 4. 2. 2.] yt = [0. 0. 1. 2. 2. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 2. 4. 2. 1. 2. 2.] yt = [0. 1. 2. 2. 2. 2. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 4. 3. 1. 3. 4.] yt = [1. 2. 3. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 4. 3. 4. 1. 1. 4.] yt = [1. 1. 3. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 3. 2. 1. 1. 3.] yt = [1. 1. 1. 2. 2. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 0. 4. 3. 0. 4.] yt = [0. 0. 3. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 0. 2. 3. 0. 3.] yt = [0. 0. 2. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 3. 4. 1. 3. 1.] yt = [1. 1. 3. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 0. 2. 2. 2. 2.] yt = [0. 1. 2. 2. 2. 2. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 0. 1. 1. 0. 3.] yt = [0. 0. 1. 1. 1. 2. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 1. 4. 0. 4. 3.] yt = [0. 1. 2. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 3. 1. 1. 0. 4. 4.] yt = [0. 1. 1. 1. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 4. 2. 3. 0. 4.] yt = [0. 2. 2. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 1. 3. 1. 0. 3.] yt = [0. 1. 1. 1. 2. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 2. 2. 1. 4. 4.] yt = [0. 1. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 3. 4. 0. 2. 1.] yt = [0. 1. 2. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 0. 2. 3. 1. 2. 2.] yt = [0. 1. 2. 2. 2. 3. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 2. 0. 3. 4. 0.] yt = [0. 0. 2. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 4. 2. 2. 4. 0.] yt = [0. 2. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 4. 0. 0. 3. 1. 2.] yt = [0. 0. 1. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 0. 2. 4. 3. 1. 0.] yt = [0. 0. 1. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 1. 0. 4. 1. 0.] yt = [0. 0. 1. 1. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 2. 4. 3. 2. 4.] yt = [1. 2. 2. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 3. 0. 1. 4. 4.] yt = [0. 0. 1. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 1. 0. 1. 1. 2. 1.] yt = [0. 0. 1. 1. 1. 1. 2.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [1. 2. 2. 4. 0. 4. 3.] yt = [0. 1. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 1. 3. 0. 4. 2. 3.] yt = [0. 1. 1. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 1. 2. 1. 1. 3.] yt = [1. 1. 1. 2. 3. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 3. 4. 3. 2. 2.] yt = [0. 1. 2. 2. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 1. 3. 0. 1. 4. 4.] yt = [0. 0. 1. 1. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 3. 2. 1. 4. 0.] yt = [0. 1. 2. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 0. 3. 2. 1. 2.] yt = [0. 0. 1. 1. 2. 2. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 4. 4. 2. 2. 0.] yt = [0. 1. 2. 2. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 1. 4. 2. 1. 4.] yt = [1. 1. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 0. 4. 0. 2. 0.] yt = [0. 0. 0. 2. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 0. 4. 0. 1. 2.] yt = [0. 0. 0. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 1. 0. 1. 0. 0. 4.] yt = [0. 0. 0. 1. 1. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 2. 2. 1. 4. 2. 0.] yt = [0. 0. 1. 2. 2. 2. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 0. 1. 1. 0. 2.] yt = [0. 0. 1. 1. 2. 2. 2.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [0. 4. 2. 4. 2. 4. 0.] yt = [0. 0. 2. 2. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 3. 3. 4. 1. 1.] yt = [0. 1. 1. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 2. 4. 1. 1. 2.] yt = [1. 1. 1. 2. 2. 2. 4.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [1. 1. 1. 4. 0. 2. 3.] yt = [0. 1. 1. 1. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 4. 4. 4. 3. 4.] yt = [0. 3. 4. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 0. 3. 3. 4. 3.] yt = [0. 0. 2. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 3. 4. 3. 3. 1.] yt = [1. 2. 2. 3. 3. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 1. 4. 0. 4. 1.] yt = [0. 0. 1. 1. 1. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 0. 1. 4. 0. 1. 2.] yt = [0. 0. 1. 1. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 1. 4. 2. 0. 4. 1.] yt = [0. 1. 1. 1. 2. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 0. 0. 2. 4. 0.] yt = [0. 0. 0. 2. 2. 2. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 2. 2. 0. 3. 2. 4.] yt = [0. 2. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 4. 3. 0. 4. 3. 4.] yt = [0. 0. 3. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 2. 2. 2. 4. 1. 4.] yt = [1. 2. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 4. 4. 1. 0. 2. 0.] yt = [0. 0. 0. 1. 2. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 0. 4. 4. 3. 0. 2.] yt = [0. 0. 1. 2. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 1. 4. 1. 4. 0.] yt = [0. 1. 1. 2. 2. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 4. 3. 4. 1. 1. 4.] yt = [1. 1. 1. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 1. 1. 3. 4. 4.] yt = [0. 1. 1. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 0. 0. 4. 2. 1. 4.] yt = [0. 0. 0. 1. 2. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 3. 0. 2. 1. 1. 1.] yt = [0. 1. 1. 1. 2. 3. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 3. 4. 4. 0. 2. 2.] yt = [0. 0. 2. 2. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 2. 1. 0. 3. 2. 0.] yt = [0. 0. 0. 1. 2. 2. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 3. 2. 3. 0. 0. 3.] yt = [0. 0. 2. 3. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 4. 4. 4. 3. 2.] yt = [2. 2. 3. 3. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 0. 1. 0. 3. 1.] yt = [0. 0. 1. 1. 1. 3. 3.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 4. 4. 0. 0. 4. 4.] yt = [0. 0. 2. 4. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 1. 1. 0. 2. 1. 4.] yt = [0. 1. 1. 1. 2. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 0. 4. 0. 0. 2. 1.] yt = [0. 0. 0. 0. 1. 2. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 2. 3. 0. 2. 4. 1.] yt = [0. 1. 2. 2. 3. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 4. 0. 3. 1. 2. 1.] yt = [0. 1. 1. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 0. 3. 4. 1. 1.] yt = [0. 1. 1. 2. 2. 3. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [0. 1. 3. 4. 0. 1. 4.] yt = [0. 0. 1. 1. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 0. 4. 3. 2. 1. 4.] yt = [0. 1. 2. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [1. 2. 4. 1. 2. 2. 1.] yt = [1. 1. 1. 2. 2. 2. 4.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [0. 0. 1. 0. 2. 2. 3.] yt = [0. 0. 0. 1. 2. 2. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 2. 1. 1. 3. 4. 3.] yt = [1. 1. 2. 2. 3. 3. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 0. 0. 2. 1. 2. 2.] yt = [0. 0. 1. 2. 2. 2. 2.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [0. 0. 0. 2. 4. 1. 2.] yt = [0. 0. 0. 1. 2. 2. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 4. 4. 1. 3. 0.] yt = [0. 1. 1. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 3. 0. 3. 1. 0. 3.] yt = [0. 0. 1. 2. 3. 3. 3.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [2. 1. 1. 2. 2. 1. 0.] yt = [0. 1. 1. 1. 2. 2. 2.] and z = [1. 4. 1. 1. 4. 2. 1.]\n",
      "xt = [2. 0. 4. 4. 0. 4. 1.] yt = [0. 0. 1. 2. 4. 4. 4.] and z = [1. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 1. 1. 0. 4. 3.] yt = [0. 1. 1. 3. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [3. 4. 2. 4. 4. 2. 3.] yt = [2. 2. 3. 3. 4. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n",
      "xt = [4. 4. 2. 2. 0. 2. 3.] yt = [0. 2. 2. 2. 3. 4. 4.] and z = [3. 4. 1. 1. 4. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "#training the module\n",
    "r = 7\n",
    "m = 5\n",
    "d = 20\n",
    "k = 10\n",
    "p = 25\n",
    "L = 2\n",
    "n_max = 2*r - 1\n",
    "n_iter = 300\n",
    "alpha = 0.001\n",
    "num_of_samples = 250\n",
    "num_train_batches = 10\n",
    "num_test_batches = 1\n",
    "\n",
    "data = get_train_test_sorting(r, m, num_of_samples, num_train_batches,num_test_batches)\n",
    "\n",
    "loss = CrossEntropy()\n",
    "feed_forward1 = FeedForward(d,p)\n",
    "attention1 = Attention(d,k)\n",
    "feed_forward2 = FeedForward(d,p)\n",
    "attention2 = Attention(d,k)\n",
    "embed_pos = EmbedPosition(n_max,m,d)\n",
    "un_embed_pos = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "layers = [embed_pos, attention1,feed_forward1,attention2, feed_forward2, un_embed_pos, softmax]\n",
    "nueralnetsort = NeuralNetwork(layers)\n",
    "\n",
    "x = data['x_train']\n",
    "y = data['y_train']\n",
    "x_t = data['x_test'][0]\n",
    "y_t = data['y_test'][0]\n",
    "\n",
    "per, y_hat = sorting(nueralnetsort, x_t, y_t,m, r)\n",
    "print(f'prosent av antall riktige sorteringer før trening er {per*100}%')\n",
    "for i in range(y_hat.shape[0]):\n",
    "    print(f'xt = {x_t[i]} yt = {y_t[i]} and z = {y_hat[i]}')\n",
    " \n",
    "#arr = algorithm_4_sort(x, y, n_iter, alpha, m, nueralnetsort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[43marr\u001b[49m)),arr)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIterasjoner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogaritmen av losset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arr' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(np.arange(len(arr)),arr)\n",
    "plt.xlabel('Iterasjoner')\n",
    "plt.ylabel('Logaritmen av losset')\n",
    "plt.title('Plot av feil for sortering')\n",
    "plt.show()\n",
    "per, z_hat = sorting(nueralnetsort, x_t, y_t,m, r)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "for i in range(250):\n",
    "    print(f'yt = {y_t[i]} and z = {z_hat[i]}')\n",
    "print(f'prosent av antall riktige sorteringer etter trening er {per*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 - Addisjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/0pv5jqcs6h34_x160t92550h0000gn/T/ipykernel_11618/2640456503.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from layers import *\n",
    "from neural_network import NeuralNetwork\n",
    "from utils import onehot\n",
    "from data_generators import get_train_test_addition\n",
    "from training import *\n",
    "\n",
    "datapunkter = 150\n",
    "batches = 20\n",
    "\n",
    "d = 30\n",
    "k = 20\n",
    "p = 40\n",
    "L = 3\n",
    "m = 10\n",
    "r = 2\n",
    "n_max = r*3\n",
    "n_iter = 250\n",
    "alpha = 0.001\n",
    "\n",
    "data_add = get_train_test_addition(r, datapunkter, batches)\n",
    "\n",
    "feed_forward1 = FeedForward(d,p)\n",
    "attention1 = Attention(d,k)\n",
    "feed_forward2 = FeedForward(d,p)\n",
    "attention2 = Attention(d,k)\n",
    "feed_forward3 = FeedForward(d,p)\n",
    "attention3 = Attention(d,k)\n",
    "feed_forward4 = FeedForward(d,p)\n",
    "attention4 = Attention(d,k)\n",
    "embed_pos = EmbedPosition(n_max,m,d)\n",
    "un_embed_pos = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "layers = [embed_pos, attention1, feed_forward1, attention2, feed_forward2, attention3, feed_forward3, un_embed_pos, softmax]\n",
    "nueralnetadd = NeuralNetwork(layers)\n",
    "\n",
    "x_add = data_add['x_train']\n",
    "y_add = data_add['y_train']\n",
    "y_add_t = data_add['y_test'][0]\n",
    "x_add_t = data_add['x_test'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one-hot encoded X in accuracy_addition: (150, 10, 4)\n",
      "Shape of one-hot encoded X in accuracy_addition: (150, 10, 5)\n",
      "prosent av antall riktige addisjoner før trening er 0.0%\n",
      "x = [1 1 6 5] y = [0 7 6], z = [5 3 6]\n",
      "x = [3 2 4 9] y = [0 8 1], z = [9 3 6]\n",
      "x = [7 8 1 7] y = [0 9 5], z = [7 4 4]\n",
      "x = [3 3 7 2] y = [1 0 5], z = [2 3 6]\n",
      "x = [2 7 1 2] y = [0 3 9], z = [2 6 7]\n",
      "x = [4 0 5 2] y = [0 9 2], z = [2 3 6]\n",
      "x = [7 2 4 3] y = [1 1 5], z = [3 3 6]\n",
      "x = [2 0 6 0] y = [0 8 0], z = [0 3 6]\n",
      "x = [4 8 1 7] y = [0 6 5], z = [7 4 4]\n",
      "x = [5 0 2 8] y = [0 7 8], z = [8 3 6]\n"
     ]
    }
   ],
   "source": [
    "per, z_hat = accuracy_addition(nueralnetadd, x_add_t, y_add_t, m,r)\n",
    "print(f'prosent av antall riktige addisjoner før trening er {per*100}%')\n",
    "\n",
    "# print first 10 datapoints\n",
    "for i in range(10):\n",
    "    print(f'x = {x_add_t[i]} y = {y_add_t[i]}, z = {z_hat[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150, Average Loss: 0.7383940381968407\n",
      "Epoch 20/150, Average Loss: 0.689511553723053\n",
      "Epoch 30/150, Average Loss: 0.6736594104127391\n",
      "Epoch 40/150, Average Loss: 0.684021517097582\n",
      "Epoch 50/150, Average Loss: 0.6869120186734047\n",
      "Epoch 60/150, Average Loss: 0.7143153865762527\n",
      "Epoch 70/150, Average Loss: 0.6954810580542258\n",
      "Epoch 80/150, Average Loss: 0.8087219501067983\n",
      "Epoch 90/150, Average Loss: 0.7564168644535674\n",
      "Epoch 100/150, Average Loss: 0.7516110588477275\n",
      "Epoch 110/150, Average Loss: 0.7460575393958976\n",
      "Epoch 120/150, Average Loss: 0.7484846365946795\n",
      "Epoch 130/150, Average Loss: 0.7439994416815997\n",
      "Epoch 140/150, Average Loss: 0.7498729565000296\n",
      "Epoch 150/150, Average Loss: 0.7394992667298407\n"
     ]
    }
   ],
   "source": [
    "addrr2 = algorithm_4_addition_finished(x_add, y_add, n_iter, alpha, m, nueralnetadd, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prosent av antall riktige addisjoner før trening er 0.0%\n",
      "xt= [6 3 1 5], yt = [0 7 8] and z = [2 0 0]\n",
      "xt= [4 1 0 7], yt = [0 4 8] and z = [6 0 1]\n",
      "xt= [0 4 7 4], yt = [0 7 8] and z = [3 0 1]\n",
      "xt= [4 3 1 7], yt = [0 6 0] and z = [9 0 1]\n",
      "xt= [8 7 0 3], yt = [0 9 0] and z = [1 1 1]\n",
      "xt= [2 5 9 6], yt = [1 2 1] and z = [0 0 1]\n",
      "xt= [1 5 3 9], yt = [0 5 4] and z = [9 0 0]\n",
      "xt= [3 8 4 9], yt = [0 8 7] and z = [2 0 1]\n",
      "xt= [1 1 6 5], yt = [0 7 6] and z = [2 0 1]\n",
      "xt= [2 9 3 5], yt = [0 6 4] and z = [2 0 0]\n",
      "xt= [5 3 7 6], yt = [1 2 9] and z = [0 0 1]\n",
      "xt= [1 1 9 8], yt = [1 0 9] and z = [0 0 1]\n",
      "xt= [0 8 6 3], yt = [0 7 1] and z = [0 0 1]\n",
      "xt= [8 1 7 9], yt = [1 6 0] and z = [3 1 1]\n",
      "xt= [0 4 9 5], yt = [0 9 9] and z = [2 0 1]\n",
      "xt= [6 7 9 6], yt = [1 6 3] and z = [1 1 1]\n",
      "xt= [1 1 6 1], yt = [0 7 2] and z = [0 0 0]\n",
      "xt= [8 2 6 9], yt = [1 5 1] and z = [3 0 1]\n",
      "xt= [0 3 0 8], yt = [0 1 1] and z = [9 9 0]\n",
      "xt= [7 7 5 4], yt = [1 3 1] and z = [3 1 1]\n",
      "xt= [7 7 2 3], yt = [1 0 0] and z = [6 0 1]\n",
      "xt= [1 2 4 5], yt = [0 5 7] and z = [2 0 1]\n",
      "xt= [2 5 3 9], yt = [0 6 4] and z = [9 0 0]\n",
      "xt= [8 2 8 7], yt = [1 6 9] and z = [3 1 1]\n",
      "xt= [9 1 6 1], yt = [1 5 2] and z = [1 1 1]\n",
      "xt= [6 7 7 3], yt = [1 4 0] and z = [1 1 1]\n",
      "xt= [5 2 6 3], yt = [1 1 5] and z = [0 0 1]\n",
      "xt= [5 0 2 8], yt = [0 7 8] and z = [0 0 0]\n",
      "xt= [8 6 2 2], yt = [1 0 8] and z = [3 0 1]\n",
      "xt= [1 3 6 2], yt = [0 7 5] and z = [0 0 1]\n",
      "xt= [6 5 0 0], yt = [0 6 5] and z = [0 0 1]\n",
      "xt= [4 7 7 1], yt = [1 1 8] and z = [1 1 1]\n",
      "xt= [4 2 8 1], yt = [1 2 3] and z = [1 1 1]\n",
      "xt= [9 5 1 9], yt = [1 1 4] and z = [0 0 1]\n",
      "xt= [3 5 8 7], yt = [1 2 2] and z = [5 0 1]\n",
      "xt= [0 3 9 9], yt = [1 0 2] and z = [0 0 1]\n",
      "xt= [6 8 4 2], yt = [1 1 0] and z = [0 0 1]\n",
      "xt= [9 2 6 0], yt = [1 5 2] and z = [8 0 1]\n",
      "xt= [5 1 1 3], yt = [0 6 4] and z = [0 0 0]\n",
      "xt= [9 7 8 4], yt = [1 8 1] and z = [1 1 1]\n",
      "xt= [0 3 8 0], yt = [0 8 3] and z = [5 2 1]\n",
      "xt= [7 4 1 8], yt = [0 9 2] and z = [0 0 1]\n",
      "xt= [5 2 8 2], yt = [1 3 4] and z = [5 0 1]\n",
      "xt= [4 7 2 8], yt = [0 7 5] and z = [0 0 1]\n",
      "xt= [6 8 8 8], yt = [1 5 6] and z = [0 1 1]\n",
      "xt= [5 8 4 6], yt = [1 0 4] and z = [0 0 1]\n",
      "xt= [2 0 5 9], yt = [0 7 9] and z = [9 0 1]\n",
      "xt= [0 6 7 5], yt = [0 8 1] and z = [2 0 1]\n",
      "xt= [1 4 3 1], yt = [0 4 5] and z = [0 0 0]\n",
      "xt= [4 4 5 2], yt = [0 9 6] and z = [0 0 1]\n",
      "xt= [2 9 4 8], yt = [0 7 7] and z = [0 0 1]\n",
      "xt= [1 3 5 0], yt = [0 6 3] and z = [9 0 1]\n",
      "xt= [3 0 0 5], yt = [0 3 5] and z = [9 0 0]\n",
      "xt= [0 8 1 8], yt = [0 2 6] and z = [9 0 0]\n",
      "xt= [7 8 3 4], yt = [1 1 2] and z = [3 0 1]\n",
      "xt= [8 2 9 9], yt = [1 8 1] and z = [3 1 1]\n",
      "xt= [6 3 4 6], yt = [1 0 9] and z = [0 0 1]\n",
      "xt= [3 3 2 4], yt = [0 5 7] and z = [3 0 0]\n",
      "xt= [5 2 1 5], yt = [0 6 7] and z = [2 0 0]\n",
      "xt= [8 9 5 7], yt = [1 4 6] and z = [6 0 1]\n",
      "xt= [8 8 6 7], yt = [1 5 5] and z = [6 0 1]\n",
      "xt= [7 2 7 4], yt = [1 4 6] and z = [3 1 1]\n",
      "xt= [9 9 2 3], yt = [1 2 2] and z = [1 1 1]\n",
      "xt= [0 0 1 0], yt = [0 1 0] and z = [9 9 0]\n",
      "xt= [0 9 1 6], yt = [0 2 5] and z = [9 0 0]\n",
      "xt= [7 0 6 2], yt = [1 3 2] and z = [3 0 1]\n",
      "xt= [5 8 4 3], yt = [1 0 1] and z = [0 0 1]\n",
      "xt= [1 2 8 6], yt = [0 9 8] and z = [0 0 1]\n",
      "xt= [1 3 5 7], yt = [0 7 0] and z = [9 0 1]\n",
      "xt= [4 3 8 7], yt = [1 3 0] and z = [5 0 1]\n",
      "xt= [3 8 1 3], yt = [0 5 1] and z = [0 0 0]\n",
      "xt= [1 6 7 1], yt = [0 8 7] and z = [0 0 1]\n",
      "xt= [0 2 2 1], yt = [0 2 3] and z = [0 9 0]\n",
      "xt= [6 4 6 1], yt = [1 2 5] and z = [0 0 1]\n",
      "xt= [4 5 9 6], yt = [1 4 1] and z = [0 0 1]\n",
      "xt= [1 4 0 6], yt = [0 2 0] and z = [9 0 0]\n",
      "xt= [9 5 6 9], yt = [1 6 4] and z = [8 0 1]\n",
      "xt= [6 5 5 9], yt = [1 2 4] and z = [0 0 1]\n",
      "xt= [6 6 1 5], yt = [0 8 1] and z = [2 0 0]\n",
      "xt= [4 4 7 2], yt = [1 1 6] and z = [0 0 1]\n",
      "xt= [6 8 1 8], yt = [0 8 6] and z = [0 0 0]\n",
      "xt= [0 6 1 4], yt = [0 2 0] and z = [3 0 0]\n",
      "xt= [5 2 6 1], yt = [1 1 3] and z = [0 0 1]\n",
      "xt= [8 8 5 5], yt = [1 4 3] and z = [6 0 1]\n",
      "xt= [1 5 1 2], yt = [0 2 7] and z = [0 0 0]\n",
      "xt= [4 5 2 5], yt = [0 7 0] and z = [2 0 0]\n",
      "xt= [3 4 4 7], yt = [0 8 1] and z = [5 0 1]\n",
      "xt= [7 8 9 9], yt = [1 7 7] and z = [3 1 1]\n",
      "xt= [4 8 3 3], yt = [0 8 1] and z = [0 0 1]\n",
      "xt= [9 8 5 7], yt = [1 5 5] and z = [6 1 1]\n",
      "xt= [2 0 9 4], yt = [1 1 4] and z = [0 0 1]\n",
      "xt= [7 8 0 9], yt = [0 8 7] and z = [9 0 1]\n",
      "xt= [8 7 2 6], yt = [1 1 3] and z = [8 0 1]\n",
      "xt= [0 7 8 3], yt = [0 9 0] and z = [0 0 1]\n",
      "xt= [5 9 8 7], yt = [1 4 6] and z = [5 0 1]\n",
      "xt= [7 6 6 3], yt = [1 3 9] and z = [1 1 1]\n",
      "xt= [2 8 4 5], yt = [0 7 3] and z = [2 0 1]\n",
      "xt= [0 2 3 6], yt = [0 3 8] and z = [9 0 0]\n",
      "xt= [7 2 9 1], yt = [1 6 3] and z = [1 1 1]\n",
      "xt= [4 1 2 5], yt = [0 6 6] and z = [2 0 0]\n",
      "xt= [3 8 0 8], yt = [0 4 6] and z = [9 0 1]\n",
      "xt= [0 3 4 5], yt = [0 4 8] and z = [2 0 1]\n",
      "xt= [4 6 1 3], yt = [0 5 9] and z = [0 0 0]\n",
      "xt= [8 0 3 2], yt = [1 1 2] and z = [3 0 1]\n",
      "xt= [3 1 4 8], yt = [0 7 9] and z = [0 0 1]\n",
      "xt= [9 6 5 4], yt = [1 5 0] and z = [3 1 1]\n",
      "xt= [7 9 6 2], yt = [1 4 1] and z = [1 1 1]\n",
      "xt= [8 9 2 9], yt = [1 1 8] and z = [3 0 1]\n",
      "xt= [6 6 3 1], yt = [0 9 7] and z = [0 0 1]\n",
      "xt= [7 7 4 5], yt = [1 2 2] and z = [6 0 1]\n",
      "xt= [3 5 5 0], yt = [0 8 5] and z = [5 0 1]\n",
      "xt= [2 3 7 7], yt = [1 0 0] and z = [5 0 1]\n",
      "xt= [1 1 4 7], yt = [0 5 8] and z = [9 0 1]\n",
      "xt= [7 0 5 5], yt = [1 2 5] and z = [6 0 1]\n",
      "xt= [6 6 0 1], yt = [0 6 7] and z = [0 0 0]\n",
      "xt= [4 1 5 8], yt = [0 9 9] and z = [0 0 1]\n",
      "xt= [6 1 2 3], yt = [0 8 4] and z = [0 0 0]\n",
      "xt= [3 3 3 7], yt = [0 7 0] and z = [5 0 0]\n",
      "xt= [9 1 0 4], yt = [0 9 5] and z = [3 0 1]\n",
      "xt= [2 8 8 8], yt = [1 1 6] and z = [0 0 1]\n",
      "xt= [4 4 1 1], yt = [0 5 5] and z = [0 0 0]\n",
      "xt= [1 9 7 5], yt = [0 9 4] and z = [0 0 1]\n",
      "xt= [5 4 7 2], yt = [1 2 6] and z = [1 1 1]\n",
      "xt= [6 8 2 2], yt = [0 9 0] and z = [0 0 0]\n",
      "xt= [1 4 4 4], yt = [0 5 8] and z = [3 0 1]\n",
      "xt= [0 7 1 8], yt = [0 2 5] and z = [9 0 0]\n",
      "xt= [2 6 3 6], yt = [0 6 2] and z = [0 0 0]\n",
      "xt= [9 9 6 5], yt = [1 6 4] and z = [6 1 1]\n",
      "xt= [7 1 2 2], yt = [0 9 3] and z = [3 0 1]\n",
      "xt= [0 4 5 1], yt = [0 5 5] and z = [0 0 1]\n",
      "xt= [2 0 0 4], yt = [0 2 4] and z = [0 0 0]\n",
      "xt= [5 4 8 9], yt = [1 4 3] and z = [0 0 1]\n",
      "xt= [6 3 6 5], yt = [1 2 8] and z = [2 0 1]\n",
      "xt= [5 7 6 2], yt = [1 1 9] and z = [0 0 1]\n",
      "xt= [5 7 1 7], yt = [0 7 4] and z = [6 0 0]\n",
      "xt= [8 0 7 1], yt = [1 5 1] and z = [1 1 1]\n",
      "xt= [7 9 7 2], yt = [1 5 1] and z = [1 1 1]\n",
      "xt= [8 7 5 5], yt = [1 4 2] and z = [6 0 1]\n",
      "xt= [2 5 8 6], yt = [1 1 1] and z = [0 0 1]\n",
      "xt= [8 4 2 8], yt = [1 1 2] and z = [0 0 1]\n",
      "xt= [9 9 2 1], yt = [1 2 0] and z = [1 1 1]\n",
      "xt= [7 1 6 8], yt = [1 3 9] and z = [0 0 1]\n",
      "xt= [5 5 3 4], yt = [0 8 9] and z = [3 0 0]\n",
      "xt= [2 1 2 1], yt = [0 4 2] and z = [0 0 0]\n",
      "xt= [6 4 8 1], yt = [1 4 5] and z = [1 1 1]\n",
      "xt= [6 8 3 2], yt = [1 0 0] and z = [0 0 1]\n",
      "xt= [5 1 6 2], yt = [1 1 3] and z = [0 0 1]\n",
      "xt= [6 5 1 4], yt = [0 7 9] and z = [9 0 0]\n",
      "xt= [7 7 5 1], yt = [1 2 8] and z = [1 1 1]\n",
      "xt= [5 5 9 0], yt = [1 4 5] and z = [0 0 1]\n",
      "xt= [4 6 9 3], yt = [1 3 9] and z = [1 1 1]\n",
      "xt= [0 8 6 8], yt = [0 7 6] and z = [0 0 1]\n",
      "xt= [2 5 0 4], yt = [0 2 9] and z = [9 0 0]\n",
      "xt= [8 7 1 9], yt = [1 0 6] and z = [0 0 1]\n",
      "xt= [8 3 5 7], yt = [1 4 0] and z = [3 1 1]\n",
      "xt= [2 8 9 3], yt = [1 2 1] and z = [1 1 1]\n",
      "xt= [3 7 1 6], yt = [0 5 3] and z = [0 0 0]\n",
      "xt= [3 7 3 4], yt = [0 7 1] and z = [2 0 0]\n",
      "xt= [8 1 6 2], yt = [1 4 3] and z = [1 1 1]\n",
      "xt= [0 4 9 8], yt = [1 0 2] and z = [0 0 1]\n",
      "xt= [8 4 8 8], yt = [1 7 2] and z = [3 1 1]\n",
      "xt= [2 4 8 9], yt = [1 1 3] and z = [0 0 1]\n",
      "xt= [2 3 6 2], yt = [0 8 5] and z = [0 0 1]\n",
      "xt= [8 3 5 2], yt = [1 3 5] and z = [3 1 1]\n",
      "xt= [6 8 1 4], yt = [0 8 2] and z = [2 0 0]\n",
      "xt= [3 1 1 7], yt = [0 4 8] and z = [9 0 0]\n",
      "xt= [4 4 4 4], yt = [0 8 8] and z = [3 0 1]\n",
      "xt= [3 1 6 2], yt = [0 9 3] and z = [0 0 1]\n",
      "xt= [9 3 5 3], yt = [1 4 6] and z = [1 1 1]\n",
      "xt= [4 3 4 3], yt = [0 8 6] and z = [0 0 1]\n",
      "xt= [2 5 6 6], yt = [0 9 1] and z = [0 0 1]\n",
      "xt= [6 5 7 0], yt = [1 3 5] and z = [5 0 1]\n",
      "xt= [4 9 6 3], yt = [1 1 2] and z = [0 0 1]\n",
      "xt= [5 7 1 5], yt = [0 7 2] and z = [2 0 0]\n",
      "xt= [3 6 1 0], yt = [0 4 6] and z = [0 0 0]\n",
      "xt= [5 9 0 8], yt = [0 6 7] and z = [0 0 1]\n",
      "xt= [4 7 5 4], yt = [1 0 1] and z = [5 0 1]\n",
      "xt= [9 0 8 2], yt = [1 7 2] and z = [1 1 1]\n",
      "xt= [0 3 6 7], yt = [0 7 0] and z = [6 0 1]\n",
      "xt= [7 8 5 5], yt = [1 3 3] and z = [6 0 1]\n",
      "xt= [7 4 0 9], yt = [0 8 3] and z = [9 0 1]\n",
      "xt= [3 1 0 6], yt = [0 3 7] and z = [9 9 0]\n",
      "xt= [6 6 8 5], yt = [1 5 1] and z = [2 1 1]\n",
      "xt= [6 1 2 7], yt = [0 8 8] and z = [9 0 1]\n",
      "xt= [8 6 9 2], yt = [1 7 8] and z = [1 1 1]\n",
      "xt= [7 6 8 5], yt = [1 6 1] and z = [6 1 1]\n",
      "xt= [7 7 2 1], yt = [0 9 8] and z = [6 0 1]\n",
      "xt= [5 2 0 9], yt = [0 6 1] and z = [9 0 1]\n",
      "xt= [0 1 7 6], yt = [0 7 7] and z = [0 0 1]\n",
      "xt= [9 3 0 0], yt = [0 9 3] and z = [1 1 1]\n",
      "xt= [8 6 4 2], yt = [1 2 8] and z = [5 0 1]\n",
      "xt= [2 2 7 6], yt = [0 9 8] and z = [0 0 1]\n",
      "xt= [6 3 3 3], yt = [0 9 6] and z = [0 0 1]\n",
      "xt= [4 6 5 7], yt = [1 0 3] and z = [0 0 1]\n",
      "xt= [6 8 4 3], yt = [1 1 1] and z = [0 0 1]\n",
      "xt= [7 3 2 6], yt = [0 9 9] and z = [0 0 1]\n",
      "xt= [9 3 4 3], yt = [1 3 6] and z = [1 1 1]\n",
      "xt= [5 6 0 5], yt = [0 6 1] and z = [2 0 0]\n",
      "xt= [5 1 5 5], yt = [1 0 6] and z = [0 0 1]\n",
      "xt= [9 9 0 1], yt = [1 0 0] and z = [1 1 1]\n",
      "xt= [3 2 7 8], yt = [1 1 0] and z = [0 0 1]\n",
      "xt= [5 8 3 8], yt = [0 9 6] and z = [0 0 0]\n",
      "xt= [5 0 0 0], yt = [0 5 0] and z = [0 0 0]\n",
      "xt= [2 6 0 8], yt = [0 3 4] and z = [9 0 0]\n",
      "xt= [6 9 1 2], yt = [0 8 1] and z = [0 0 0]\n",
      "xt= [8 5 5 0], yt = [1 3 5] and z = [3 1 1]\n",
      "xt= [4 2 6 7], yt = [1 0 9] and z = [5 0 1]\n",
      "xt= [2 1 4 8], yt = [0 6 9] and z = [9 0 1]\n",
      "xt= [5 8 6 4], yt = [1 2 2] and z = [2 0 1]\n",
      "xt= [4 5 3 5], yt = [0 8 0] and z = [2 0 1]\n",
      "xt= [1 7 2 5], yt = [0 4 2] and z = [2 0 0]\n",
      "xt= [9 9 5 0], yt = [1 4 9] and z = [3 1 1]\n",
      "xt= [0 6 4 2], yt = [0 4 8] and z = [3 0 1]\n",
      "xt= [7 1 1 9], yt = [0 9 0] and z = [9 0 1]\n",
      "xt= [2 7 2 0], yt = [0 4 7] and z = [0 0 0]\n",
      "xt= [5 3 9 9], yt = [1 5 2] and z = [0 0 1]\n",
      "xt= [0 2 9 6], yt = [0 9 8] and z = [0 0 1]\n",
      "xt= [4 9 9 8], yt = [1 4 7] and z = [0 1 1]\n",
      "xt= [2 0 4 0], yt = [0 6 0] and z = [0 0 1]\n",
      "xt= [2 0 4 3], yt = [0 6 3] and z = [0 0 1]\n",
      "xt= [0 9 8 7], yt = [0 9 6] and z = [0 0 1]\n",
      "xt= [5 0 0 7], yt = [0 5 7] and z = [0 0 1]\n",
      "xt= [7 2 9 0], yt = [1 6 2] and z = [1 1 1]\n",
      "xt= [7 0 0 4], yt = [0 7 4] and z = [3 0 1]\n",
      "xt= [7 4 4 3], yt = [1 1 7] and z = [0 0 1]\n",
      "xt= [3 6 8 7], yt = [1 2 3] and z = [5 0 1]\n",
      "xt= [0 8 2 8], yt = [0 3 6] and z = [9 0 0]\n",
      "xt= [8 0 5 6], yt = [1 3 6] and z = [0 0 1]\n",
      "xt= [4 0 1 0], yt = [0 5 0] and z = [0 0 1]\n",
      "xt= [4 1 3 1], yt = [0 7 2] and z = [0 0 1]\n",
      "xt= [6 8 7 5], yt = [1 4 3] and z = [5 0 1]\n",
      "xt= [1 7 7 6], yt = [0 9 3] and z = [0 0 1]\n",
      "xt= [2 6 0 7], yt = [0 3 3] and z = [0 0 0]\n",
      "xt= [3 7 6 6], yt = [1 0 3] and z = [0 0 1]\n",
      "xt= [4 1 9 5], yt = [1 3 6] and z = [0 0 1]\n",
      "xt= [8 5 8 8], yt = [1 7 3] and z = [3 1 1]\n",
      "xt= [5 0 9 5], yt = [1 4 5] and z = [2 1 1]\n",
      "xt= [3 0 5 5], yt = [0 8 5] and z = [2 0 1]\n",
      "xt= [1 0 7 3], yt = [0 8 3] and z = [0 0 1]\n",
      "xt= [9 3 8 2], yt = [1 7 5] and z = [1 1 1]\n",
      "xt= [3 2 1 9], yt = [0 5 1] and z = [9 0 0]\n",
      "xt= [9 6 6 9], yt = [1 6 5] and z = [8 0 1]\n",
      "xt= [1 7 1 4], yt = [0 3 1] and z = [9 0 0]\n",
      "xt= [4 3 5 5], yt = [0 9 8] and z = [0 0 1]\n",
      "xt= [7 0 8 1], yt = [1 5 1] and z = [1 1 1]\n",
      "xt= [1 9 5 8], yt = [0 7 7] and z = [0 0 1]\n",
      "xt= [9 9 8 6], yt = [1 8 5] and z = [1 1 1]\n",
      "xt= [1 8 6 4], yt = [0 8 2] and z = [2 0 1]\n",
      "xt= [8 0 2 6], yt = [1 0 6] and z = [0 0 1]\n",
      "xt= [9 5 1 6], yt = [1 1 1] and z = [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "per, z_hat = sorting(nueralnetadd, x_add_t, y_add_t, m,r+1)\n",
    "print(f'prosent av antall riktige addisjoner før trening er {per*100}%')\n",
    "\n",
    "for i in range(y_add_t.shape[0]):\n",
    "    print(f'xt= {x_add_t[i]}, yt = {y_add_t[i]} and z = {z_hat[i]}')\n",
    "\n",
    "#arr3 = algorithm_4_add(x_add, y_add, n_iter, alpha, m,r,  nueralnetadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(addrr2)),addrr2)\n",
    "plt.xlabel('Iterasjoner')\n",
    "plt.ylabel('Logaritmen av losset')\n",
    "plt.title('Plot av feil for addisjon')\n",
    "plt.show()\n",
    "\n",
    "y_add_t = data_add['y_test'][0]\n",
    "x_add_t = data_add['x_test'][0]\n",
    "\n",
    "per, z_hat = sorting(nueralnetadd, x_add_t, y_add_t,m,r+1)\n",
    "print(f'prosent av antall riktige addisjoner er {per*100}%')\n",
    "\n",
    "for i in range(y_add_t.shape[0]):\n",
    "    #print(f'x train {x[0][i]} y train{y[0][i]}')\n",
    "    print(f'yt = {y_add_t[i]} and z = {z_hat[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
